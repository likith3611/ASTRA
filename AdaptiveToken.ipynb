{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scenarionet import read_dataset_summary, read_scenario\n",
    "from metadrive.engine.asset_loader import AssetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveTokenizer:\n",
    "    def __init__(self, importance_threshold=0.5, max_tokens=512, token_length=10, use_gpu=False):\n",
    "        self.importance_threshold = importance_threshold\n",
    "        self.max_tokens = max_tokens\n",
    "        self.token_length = token_length\n",
    "        self.device = torch.device('cuda' if (use_gpu and torch.cuda.is_available()) else 'cpu')\n",
    "        self.type_importance = {\n",
    "            'VEHICLE': 1.0,\n",
    "            'PEDESTRIAN': 0.8,\n",
    "            'BICYCLE': 0.7,\n",
    "            'STATIC': 0.5,\n",
    "            'UNKNOWN': 0.3\n",
    "        }\n",
    "        self.map_feature_importance = {\n",
    "            'LANE': 0.9,\n",
    "            'CROSSWALK': 0.7,\n",
    "            'STOP_SIGN': 0.6,\n",
    "            'TRAFFIC_LIGHT': 0.8,\n",
    "            'UNKNOWN': 0.4\n",
    "        }\n",
    "\n",
    "    def score_importance(self, tracks, map_features):\n",
    "        importance_map = np.zeros(len(tracks) + len(map_features))\n",
    "        \n",
    "        for i, (track_id, track) in enumerate(tracks.items()):\n",
    "            state = track['state']\n",
    "            valid = state['valid']\n",
    "            if not valid.any():\n",
    "                importance_map[i] = 0\n",
    "                continue\n",
    "\n",
    "            valid_positions = state['position'][valid]\n",
    "            valid_velocities = state['velocity'][valid]\n",
    "            valid_headings = state['heading'][valid]\n",
    "            valid_lengths = state['length'][valid]\n",
    "            valid_widths = state['width'][valid]\n",
    "            valid_heights = state['height'][valid]\n",
    "            \n",
    "            activity_score = np.linalg.norm(valid_positions, axis=1).sum()\n",
    "            velocity_score = np.linalg.norm(valid_velocities, axis=1).sum()\n",
    "            heading_score = np.abs(valid_headings).sum()\n",
    "            size_score = valid_lengths.sum() + valid_widths.sum() + valid_heights.sum()\n",
    "            type_score = self.type_importance.get(track.get('type', 'UNKNOWN'), 0.3)\n",
    "            \n",
    "            importance_map[i] = activity_score + velocity_score + heading_score + size_score + type_score\n",
    "\n",
    "        for i, (feature_id, feature) in enumerate(map_features.items(), start=len(tracks)):\n",
    "            feature_type = feature.get('type', 'UNKNOWN')\n",
    "            polyline = feature.get('polyline', [])\n",
    "            if len(polyline) == 0:\n",
    "                importance_map[i] = 0\n",
    "                continue\n",
    "            feature_score = len(polyline) * self.map_feature_importance.get(feature_type, 0.4)\n",
    "            importance_map[i] = feature_score\n",
    "        \n",
    "        importance_map = importance_map / (importance_map.max() + 1e-5)\n",
    "        return importance_map\n",
    "\n",
    "    def pad_or_truncate(self, token, expected_dim):\n",
    "        if token.shape[1] != expected_dim:\n",
    "            token = token[:, :expected_dim] if token.shape[1] > expected_dim else np.pad(token, ((0, 0), (0, expected_dim - token.shape[1])), mode='constant')\n",
    "        if token.shape[0] > self.token_length:\n",
    "            token = token[:self.token_length]\n",
    "        else:\n",
    "            pad_length = self.token_length - token.shape[0]\n",
    "            pad = np.zeros((pad_length, expected_dim), dtype=np.float32)\n",
    "            token = np.vstack((token, pad))\n",
    "        return token\n",
    "\n",
    "    def tokenize(self, tracks, map_features, metadata):\n",
    "        importance_scores = self.score_importance(tracks, map_features)\n",
    "        track_regions = []\n",
    "        map_regions = []\n",
    "        token_types = []\n",
    "        token_ids = []\n",
    "\n",
    "        for i, (track_id, track) in enumerate(tracks.items()):\n",
    "            state = track['state']\n",
    "            valid = state['valid']\n",
    "            if not valid.any():\n",
    "                continue\n",
    "            \n",
    "            valid_positions = state['position'][valid]\n",
    "            valid_velocities = state['velocity'][valid]\n",
    "            valid_headings = state['heading'][valid]\n",
    "            valid_lengths = state['length'][valid]\n",
    "            valid_widths = state['width'][valid]\n",
    "            valid_heights = state['height'][valid]\n",
    "            \n",
    "            combined_token = np.column_stack((valid_positions, valid_velocities, valid_headings, valid_lengths, valid_widths, valid_heights))\n",
    "            token = self.pad_or_truncate(combined_token, expected_dim=9)\n",
    "            token_types.append(f'high-detail-{track.get(\"type\", \"UNKNOWN\")}')\n",
    "            track_regions.append(torch.tensor(token, dtype=torch.float32, device=self.device))\n",
    "            token_ids.append(track_id)\n",
    "\n",
    "        for i, (feature_id, feature) in enumerate(map_features.items(), start=len(tracks)):\n",
    "            polyline = feature.get('polyline', [])\n",
    "            if len(polyline) > 0:\n",
    "                polyline_array = np.array(polyline)\n",
    "                polyline_array = polyline_array[:, :2] if polyline_array.shape[1] > 2 else polyline_array\n",
    "                token = self.pad_or_truncate(polyline_array, expected_dim=2)\n",
    "                token_types.append(f'map-{feature.get(\"type\", \"UNKNOWN\")}')\n",
    "                map_regions.append(torch.tensor(token, dtype=torch.float32, device=self.device))\n",
    "                token_ids.append(feature_id)\n",
    "\n",
    "        track_tensor = torch.cat(track_regions, dim=0) if track_regions else torch.empty((0, self.token_length, 9), device=self.device)\n",
    "        map_tensor = torch.cat(map_regions, dim=0) if map_regions else torch.empty((0, self.token_length, 2), device=self.device)\n",
    "\n",
    "        return {\n",
    "            'track_regions': track_tensor,\n",
    "            'map_regions': map_tensor,\n",
    "            'token_types': token_types,\n",
    "            'token_ids': token_ids,\n",
    "            'metadata': metadata\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization Complete!\n",
      "Track Tensor Shape: torch.Size([210, 9])\n",
      "Map Tensor Shape: torch.Size([2050, 2])\n",
      "Token Types: {'map-ROAD_LINE_BROKEN_SINGLE_WHITE', 'map-ROAD_LINE_SOLID_SINGLE_WHITE', 'map-ROAD_LINE_SOLID_DOUBLE_YELLOW', 'high-detail-OTHER', 'high-detail-VEHICLE', 'map-UNKNOWN_LINE', 'map-LANE_SURFACE_STREET'}\n",
      "Token IDs: ['73980', '74036', '74140', '74157', '74167', '74225', '74231', '74250', '74252', '74253', '74254', '74256', '74262', '74263', '74264', '74271', '74275', '74276', '74286', '74290', 'AV', '942716285', '942716286', '471289997', '942716768', '942716769', '471290480', '942716831', '942716832', '471290543', '942716964', '942716965', '471290676', '942716984', '942716985', '471290696', '942717007', '942717008', '471290719', '942717015', '942717016', '471290727', '942717250', '942717251', '471290962', '942717338', '942717339', '471291050', '942717350', '942717351', '471291062', '942717352', '471291063', '942717361', '942717362', '471291073', '942717363', '942717364', '471291075', '942717385', '942717386', '471291097', '942717389', '942717390', '471291101', '942717391', '942717392', '471291103', '942717636', '942717637', '471291348', '942717639', '942717640', '471291351', '942717641', '942717642', '471291353', '942717645', '942717646', '471291357', '942717647', '942717648', '471291359', '942717664', '942717665', '471291376', '942717694', '942717695', '471291406', '942717718', '942717719', '471291430', '942717724', '942717725', '471291436', '942717833', '942717834', '471291545', '942717863', '942717864', '471291575', '942717871', '942717872', '471291583', '942717885', '942717886', '471291597', '942717888', '942717889', '471291600', '942717893', '942717894', '471291605', '942717912', '942717913', '471291624', '942717915', '942717916', '471291627', '942717917', '471291628', '942717918', '942717919', '471291630', '942717920', '471291631', '942717954', '942717955', '471291666', '942717970', '942717971', '471291682', '942717974', '942717975', '471291686', '942717980', '942717981', '471291692', '942718001', '942718002', '471291713', '942718018', '942718019', '471291730', '942718027', '942718028', '471291739', '942718233', '942718234', '471291945', '942718237', '942718238', '471291949', '942718239', '942718240', '471291951', '942718286', '942718287', '471291998', '942718289', '942718290', '471292001', '942718293', '942718294', '471292005', '942718312', '942718313', '471292024', '942718335', '942718336', '471292047', '942718337', '471292048', '942718342', '942718343', '471292054', '942718369', '942718370', '471292081', '942718386', '942718387', '471292098', '942718430', '942718431', '471292142', '942718666', '942718667', '471292378', '942718688', '942718689', '471292400', '942718704', '942718705', '471292416', '942718718', '942718719', '471292430', '942718840', '942718841', '471292552', '942718852', '942718853', '471292564', '942718858', '942718859', '471292570', '942850724', '942850725', '471424436', '942851360', '942851361', '471425072', '942852575', '942852576', '471426287', 'boundary_00', 'boundary_020', 'boundary_040', 'boundary_060', 'boundary_080', 'boundary_0100', 'boundary_0120', 'boundary_0140', 'boundary_0160', 'boundary_0180', 'boundary_0200']\n",
      "Metadata: {'id': '0a14e451-2293-4a95-ab65-184427d890f3', 'coordinate': 'waymo', 'ts': array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ,\n",
      "        1.1,  1.2,  1.3,  1.4,  1.5,  1.6,  1.7,  1.8,  1.9,  2. ,  2.1,\n",
      "        2.2,  2.3,  2.4,  2.5,  2.6,  2.7,  2.8,  2.9,  3. ,  3.1,  3.2,\n",
      "        3.3,  3.4,  3.5,  3.6,  3.7,  3.8,  3.9,  4. ,  4.1,  4.2,  4.3,\n",
      "        4.4,  4.5,  4.6,  4.7,  4.8,  4.9,  5. ,  5.1,  5.2,  5.3,  5.4,\n",
      "        5.5,  5.6,  5.7,  5.8,  5.9,  6. ,  6.1,  6.2,  6.3,  6.4,  6.5,\n",
      "        6.6,  6.7,  6.8,  6.9,  7. ,  7.1,  7.2,  7.3,  7.4,  7.5,  7.6,\n",
      "        7.7,  7.8,  7.9,  8. ,  8.1,  8.2,  8.3,  8.4,  8.5,  8.6,  8.7,\n",
      "        8.8,  8.9,  9. ,  9.1,  9.2,  9.3,  9.4,  9.5,  9.6,  9.7,  9.8,\n",
      "        9.9, 10. , 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7, 10.8, 10.9]), 'metadrive_processed': False, 'sdc_id': 'AV', 'dataset': 'av2', 'scenario_id': '0a14e451-2293-4a95-ab65-184427d890f3', 'source_file': '0a14e451-2293-4a95-ab65-184427d890f3', 'track_length': 110, 'current_time_index': 49, 'objects_of_interest': [], 'sdc_track_index': 20, 'tracks_to_predict': {'73980': {'track_index': 0, 'track_id': '73980', 'difficulty': 0, 'object_type': 'VEHICLE'}}, 'object_summary': {'73980': {'type': 'VEHICLE', 'object_id': '73980', 'track_length': 110, 'moving_distance': 83.07073974609375, 'valid_length': 110, 'continuous_valid_length': 110}, '74036': {'type': 'VEHICLE', 'object_id': '74036', 'track_length': 110, 'moving_distance': 3.012420415878296, 'valid_length': 33, 'continuous_valid_length': 33}, '74140': {'type': 'VEHICLE', 'object_id': '74140', 'track_length': 110, 'moving_distance': 0.10854719579219818, 'valid_length': 28, 'continuous_valid_length': 28}, '74157': {'type': 'VEHICLE', 'object_id': '74157', 'track_length': 110, 'moving_distance': 0.20654280483722687, 'valid_length': 21, 'continuous_valid_length': 21}, '74167': {'type': 'VEHICLE', 'object_id': '74167', 'track_length': 110, 'moving_distance': 0.1667182743549347, 'valid_length': 18, 'continuous_valid_length': 18}, '74225': {'type': 'VEHICLE', 'object_id': '74225', 'track_length': 110, 'moving_distance': 0.23332378268241882, 'valid_length': 19, 'continuous_valid_length': 19}, '74231': {'type': 'OTHER', 'object_id': '74231', 'track_length': 110, 'moving_distance': 2.7098162174224854, 'valid_length': 89, 'continuous_valid_length': 89}, '74250': {'type': 'OTHER', 'object_id': '74250', 'track_length': 110, 'moving_distance': 1.5489386320114136, 'valid_length': 17, 'continuous_valid_length': 17}, '74252': {'type': 'OTHER', 'object_id': '74252', 'track_length': 110, 'moving_distance': 2.6362509727478027, 'valid_length': 38, 'continuous_valid_length': 38}, '74253': {'type': 'VEHICLE', 'object_id': '74253', 'track_length': 110, 'moving_distance': 2.150221824645996, 'valid_length': 85, 'continuous_valid_length': 85}, '74254': {'type': 'VEHICLE', 'object_id': '74254', 'track_length': 110, 'moving_distance': 2.027728796005249, 'valid_length': 81, 'continuous_valid_length': 81}, '74256': {'type': 'VEHICLE', 'object_id': '74256', 'track_length': 110, 'moving_distance': 3.0412142276763916, 'valid_length': 75, 'continuous_valid_length': 75}, '74262': {'type': 'VEHICLE', 'object_id': '74262', 'track_length': 110, 'moving_distance': 4.149805545806885, 'valid_length': 11, 'continuous_valid_length': 11}, '74263': {'type': 'VEHICLE', 'object_id': '74263', 'track_length': 110, 'moving_distance': 43.59075927734375, 'valid_length': 65, 'continuous_valid_length': 65}, '74264': {'type': 'VEHICLE', 'object_id': '74264', 'track_length': 110, 'moving_distance': 50.82166290283203, 'valid_length': 33, 'continuous_valid_length': 33}, '74271': {'type': 'VEHICLE', 'object_id': '74271', 'track_length': 110, 'moving_distance': 16.355072021484375, 'valid_length': 41, 'continuous_valid_length': 41}, '74275': {'type': 'VEHICLE', 'object_id': '74275', 'track_length': 110, 'moving_distance': 16.828935623168945, 'valid_length': 16, 'continuous_valid_length': 16}, '74276': {'type': 'OTHER', 'object_id': '74276', 'track_length': 110, 'moving_distance': 0.9038136005401611, 'valid_length': 27, 'continuous_valid_length': 27}, '74286': {'type': 'VEHICLE', 'object_id': '74286', 'track_length': 110, 'moving_distance': 1.7012447118759155, 'valid_length': 22, 'continuous_valid_length': 22}, '74290': {'type': 'VEHICLE', 'object_id': '74290', 'track_length': 110, 'moving_distance': 15.241682052612305, 'valid_length': 18, 'continuous_valid_length': 18}, 'AV': {'type': 'VEHICLE', 'object_id': 'AV', 'track_length': 110, 'moving_distance': 71.94290161132812, 'valid_length': 110, 'continuous_valid_length': 110}}, 'number_summary': {'num_objects': 21, 'object_types': {'VEHICLE', 'OTHER'}, 'num_objects_each_type': {'VEHICLE': 17, 'OTHER': 4}, 'num_moving_objects': 16, 'num_moving_objects_each_type': defaultdict(<class 'int'>, {'VEHICLE': 13, 'OTHER': 3}), 'num_traffic_lights': 0, 'num_traffic_light_types': set(), 'num_traffic_light_each_step': {}, 'num_map_features': 212, 'map_height_diff': 4.300000190734863}}\n"
     ]
    }
   ],
   "source": [
    "sample_tracks = {\n",
    "        'track_1': {'state': {'position': np.random.rand(10, 3), 'velocity': np.random.rand(10, 2), 'heading': np.random.rand(10), \n",
    "                              'length': np.random.rand(10), 'width': np.random.rand(10), 'height': np.random.rand(10), \n",
    "                              'valid': np.array([True] * 10)}, 'type': 'VEHICLE'}\n",
    "    }\n",
    "sample_map_features = {\n",
    "        'lane_1': {'type': 'LANE', 'polyline': np.random.rand(5, 2)}\n",
    "    }\n",
    "sample_metadata = {'scenario_id': 'sample_001', 'map': 'city_map_1'}\n",
    "\n",
    "tokenizer = AdaptiveTokenizer(token_length=10, use_gpu=True)\n",
    "tokens = tokenizer.tokenize(scenario[\"tracks\"], scenario[\"map_features\"], scenario[\"metadata\"])\n",
    "\n",
    "print(\"Tokenization Complete!\")\n",
    "print(f\"Track Tensor Shape: {tokens['track_regions'].shape}\")\n",
    "print(f\"Map Tensor Shape: {tokens['map_regions'].shape}\")\n",
    "print(f\"Token Types: {set(tokens['token_types'])}\")\n",
    "print(f\"Token IDs: {tokens['token_ids']}\")\n",
    "print(f\"Metadata: {tokens['metadata']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.7942e+03,  1.3763e+03,  0.0000e+00,  4.8375e+00, -5.1642e+00,\n",
       "        -8.1722e-01,  4.0000e+00,  2.0000e+00,  1.0000e+00], device='cuda:0')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['track_regions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "av2_data =  AssetLoader.file_path(\"/home/light/Documents/Thesis/preprocessed_dataset\", unix_style=False)\n",
    "dataset_summary, scenario_ids, mapping = read_dataset_summary(dataset_path=av2_data)\n",
    "\n",
    "scenario_file_name = scenario_ids[0]\n",
    "scenario = read_scenario(dataset_path=av2_data, mapping=mapping, scenario_file_name=scenario_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'version', 'length', 'tracks', 'dynamic_map_states', 'map_features', 'metadata'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
