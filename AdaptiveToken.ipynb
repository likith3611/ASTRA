{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scenarionet import read_dataset_summary, read_scenario\n",
    "from metadrive.engine.asset_loader import AssetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveTokenizer:\n",
    "    def __init__(self, importance_threshold=0.5, max_tokens=512, token_length=10):\n",
    "        self.importance_threshold = importance_threshold\n",
    "        self.max_tokens = max_tokens\n",
    "        self.token_length = token_length\n",
    "    def score_importance(self, trajectories, road_vectors):\n",
    "        importance_map = np.zeros(trajectories.shape[0])\n",
    "        for i in range(trajectories.shape[0]):\n",
    "            activity_score = np.linalg.norm(trajectories[i, :, :2], axis=1).sum()\n",
    "            distances = np.linalg.norm(\n",
    "                road_vectors[:, None, :] - trajectories[i, :, :2][None, :, :], axis=2\n",
    "            )\n",
    "            \n",
    "            road_proximity = np.min(distances)\n",
    "            \n",
    "            importance_map[i] = activity_score / (road_proximity + 1e-5)\n",
    "        \n",
    "        importance_map = importance_map / (importance_map.max() + 1e-5)\n",
    "        return importance_map\n",
    "\n",
    "    def pad_or_truncate(self, token):\n",
    "        if token.shape[0] > self.token_length:\n",
    "            return token[:self.token_length]\n",
    "        else:\n",
    "            pad_length = self.token_length - token.shape[0]\n",
    "            pad = np.zeros((pad_length, token.shape[1]), dtype=np.float32)\n",
    "            return np.vstack((token, pad))\n",
    "\n",
    "    def tokenize(self, trajectories, road_vectors, metadata):\n",
    "        importance_scores = self.score_importance(trajectories, road_vectors)\n",
    "        token_regions = []\n",
    "        token_types = []\n",
    "\n",
    "        for i, score in enumerate(importance_scores):\n",
    "            if score >= self.importance_threshold:\n",
    "                token = self.pad_or_truncate(trajectories[i])\n",
    "                token_regions.append(token)\n",
    "                token_types.append('high-detail')\n",
    "            else:\n",
    "                coarse_token = self.pad_or_truncate(trajectories[i][::2]) \n",
    "                token_regions.append(coarse_token)\n",
    "                token_types.append('low-detail')\n",
    "        if len(token_regions) > self.max_tokens:\n",
    "            token_regions = token_regions[:self.max_tokens]\n",
    "            token_types = token_types[:self.max_tokens]\n",
    "\n",
    "        try:\n",
    "            token_tensor = torch.tensor(np.stack(token_regions), dtype=torch.float32)\n",
    "        except ValueError as e:\n",
    "            raise ValueError(\"Failed to stack token regions into a tensor. Ensure all tokens have the same dimensions.\") from e\n",
    "\n",
    "        tokens = {\n",
    "            'token_regions': token_tensor,\n",
    "            'token_types': token_types,\n",
    "            'metadata': metadata\n",
    "        }\n",
    "        return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization Complete!\n",
      "Number of Tokens: 100\n",
      "Token Types: {'low-detail', 'high-detail'}\n",
      "Metadata: {'scenario_id': 'sample_001', 'map': 'city_map_1'}\n"
     ]
    }
   ],
   "source": [
    "sample_trajectories = np.random.rand(100, 10, 3)\n",
    "sample_road_vectors = np.random.rand(50, 2) \n",
    "sample_metadata = {'scenario_id': 'sample_001', 'map': 'city_map_1'}\n",
    "tokenizer = AdaptiveTokenizer()\n",
    "tokens = tokenizer.tokenize(sample_trajectories, sample_road_vectors, sample_metadata)\n",
    "print(\"Tokenization Complete!\")\n",
    "print(f\"Number of Tokens: {len(tokens['token_regions'])}\")\n",
    "print(f\"Token Types: {set(tokens['token_types'])}\")\n",
    "print(f\"Metadata: {tokens['metadata']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "av2_data =  AssetLoader.file_path(\"/home/light/Documents/Thesis/preprocessed_dataset\", unix_style=False)\n",
    "dataset_summary, scenario_ids, mapping = read_dataset_summary(dataset_path=av2_data)\n",
    "\n",
    "scenario_file_name = scenario_ids[0]\n",
    "scenario = read_scenario(dataset_path=av2_data, mapping=mapping, scenario_file_name=scenario_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['type', 'state', 'metadata'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenario[\"tracks\"][\"73980\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
